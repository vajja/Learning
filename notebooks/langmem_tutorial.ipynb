{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### Importing required libraries\n",
    "* from .env loading OpenAI key and other environment variables\n",
    "* Official blog: <a href=\"https://langchain-ai.github.io/langmem/\">link</a>"
   ],
   "id": "80e08b4ed41293fd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b1f01791d551a161"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4f97691880d9cf0c"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-27T12:50:22.801449Z",
     "start_time": "2025-10-27T12:50:20.964289Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1,
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.store.memory import InMemoryStore     # for demo; use AsyncPostgresStore in prod\n",
    "\n",
    "\n",
    "# ---- LangMem: tools + background manager + (optional) short-term summarization helpers\n",
    "from langmem import (\n",
    "    create_manage_memory_tool,       # Hot-path tool to create/update/delete memories\n",
    "    create_search_memory_tool,       # (Optional) Hot-path search tool\n",
    ")\n",
    "from langmem.short_term import summarize_messages, RunningSummary  # optional\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ],
   "id": "68f1880ca1a3a3b2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "* Choose the embedding model which we want to use the conversational information",
   "id": "a3a3283a21311370"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T12:50:23.053287Z",
     "start_time": "2025-10-27T12:50:22.909431Z"
    }
   },
   "cell_type": "code",
   "source": "store = InMemoryStore(index={\"embed\": \"openai:text-embedding-3-small\", \"dims\": 1536})",
   "id": "6270e1fc98469b5b",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9a31047bf9119c4d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "* Once the instance killed we will lose this memory being created now.\n",
    "* It keeps increasing as it's internally handled keeps increasing till the instance is terminated.\n",
    "* <b>Langmem</b>\n",
    "    * Purpose‚Äêbuilt memory framework for agents:\n",
    "        * Extraction, consolidation, namespaces, types of memory (semantic/episodic/procedural).\n",
    "        * Simplifies memory management tasks (insert/update/delete, background managers, tools).\n",
    "* Please check if we can replicate it with <b>vector database</b>\n",
    "    * Drawback is it doesn't provide memory logic\n",
    "    * We have to again write custom logic on top of this results from vectordb"
   ],
   "id": "b701f168a5f400bd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T12:50:25.596280Z",
     "start_time": "2025-10-27T12:50:25.589373Z"
    }
   },
   "cell_type": "code",
   "source": [
    "manage_memory_tool = create_manage_memory_tool(\n",
    "    namespace=(\"memories\", \"{langgraph_user_id}\", \"collection\"),\n",
    "    # Limit what the LLM is allowed to do if you prefer:\n",
    "    # actions_permitted=(\"create\", \"update\", \"delete\"),\n",
    "    store=store\n",
    ")"
   ],
   "id": "51d2c8fc7fda7663",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c2a9108f4296e7a4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "* It allows to search on the vector store data which was created by <b>manage_memory_tool</b>",
   "id": "43e88fbe670e346d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T12:50:27.307226Z",
     "start_time": "2025-10-27T12:50:27.300639Z"
    }
   },
   "cell_type": "code",
   "source": [
    "search_memory_tool = create_search_memory_tool(\n",
    "    namespace=(\"memories\", \"{langgraph_user_id}\", \"collection\"),\n",
    "    store=store\n",
    ")\n"
   ],
   "id": "d9488c5709ad18c6",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4f30069e3472a5f5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T12:50:28.925366Z",
     "start_time": "2025-10-27T12:50:28.922494Z"
    }
   },
   "cell_type": "code",
   "source": [
    "profile = {\n",
    "    \"name\": \"Ram\",\n",
    "    \"full_name\": \"Ram\",\n",
    "    \"user_profile_background\": \"You are the ruler of the world.\",\n",
    "}"
   ],
   "id": "709fb9fe936548bf",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "be5d34cb401145bf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T12:50:30.925589Z",
     "start_time": "2025-10-27T12:50:30.923229Z"
    }
   },
   "cell_type": "code",
   "source": [
    "agent_system_prompt_memory = \"\"\"\n",
    "< Role >\n",
    "You are AI executive chat assistant. You are a capable of answering anything at ease using your knowledge. You can use your knowledge and history of conversation to answer the user's questions in a professional manner.\n",
    "</ Role >\n",
    "\n",
    "< Tools >\n",
    "You have access to the following tools to help manage {name}'s communications and schedule:\n",
    "1. manage_memory - Store any relevant information about contacts, actions, discussion, etc. in memory for future reference\n",
    "2. search_memory - Search for any relevant information that may have been stored in memory\n",
    "</ Tools >\n",
    "\n",
    "< Instructions >\n",
    "{instructions}\n",
    "</ Instructions >\n",
    "\"\"\""
   ],
   "id": "1fa26a1face00174",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a06fd42713fadf27"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T12:50:38.784309Z",
     "start_time": "2025-10-27T12:50:38.781320Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_prompt(state):\n",
    "    return [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": agent_system_prompt_memory.format(\n",
    "                instructions=\"Use these tools when appropriate to help manage Rams's tasks efficiently.\",\n",
    "                **profile\n",
    "            )\n",
    "        }\n",
    "    ] + state['messages']"
   ],
   "id": "5965ad0ea79ac250",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4d092cf5fe0bb250"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T12:50:40.547461Z",
     "start_time": "2025-10-27T12:50:40.544860Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tools= [\n",
    "    # memory_manger,\n",
    "    manage_memory_tool,\n",
    "    search_memory_tool\n",
    "]\n"
   ],
   "id": "7f3ad9eb58a56b4c",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f837f05ac31c8fd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "* React agent\n",
    "    * Give tools available\n",
    "    * Prompt\n",
    "    * If required for the usecase it would use the tools for our usecase depending on the prompt and the input.\n",
    "    * It does execute using the tool\n",
    "    * Here it uses these tools for managing memory:\n",
    "        * <b>manage_memory_tool</b>\n",
    "        * <b>search_memory_tool</b>"
   ],
   "id": "4a973e9968592525"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T12:50:43.437153Z",
     "start_time": "2025-10-27T12:50:43.407185Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response_agent = create_react_agent(\n",
    "    \"openai:gpt-4o-mini\",\n",
    "    tools=tools,\n",
    "    prompt=create_prompt,\n",
    "    # Use this to ensure the store is passed to the agent\n",
    "    store=store\n",
    ")"
   ],
   "id": "547963d1034ce5bf",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "23b0b66b1cba6621"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T12:50:45.821873Z",
     "start_time": "2025-10-27T12:50:45.818569Z"
    }
   },
   "cell_type": "code",
   "source": "config = {\"configurable\": {\"langgraph_user_id\": \"session-id-test\"}}",
   "id": "d853c0b495b134f7",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d8db81a9cafba74a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "662b196ffe0fd2dc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "* Using react agent",
   "id": "663e97d846ea9338"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T12:50:53.390129Z",
     "start_time": "2025-10-27T12:50:49.651411Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response = response_agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"My name is Ram.\"}]},\n",
    "    config=config\n",
    ")"
   ],
   "id": "8c561a25b2bf7bdc",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T12:50:53.404116Z",
     "start_time": "2025-10-27T12:50:53.400695Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for m in response[\"messages\"]:\n",
    "    m.pretty_print()"
   ],
   "id": "abc9e691bb3cf8bc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "My name is Ram.\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  manage_memory (call_SSzEd4uZ17go5QqyNpDFYlcI)\n",
      " Call ID: call_SSzEd4uZ17go5QqyNpDFYlcI\n",
      "  Args:\n",
      "    content: User's name is Ram.\n",
      "    action: create\n",
      "=================================\u001B[1m Tool Message \u001B[0m=================================\n",
      "Name: manage_memory\n",
      "\n",
      "created memory b5bb66e7-5f5d-4170-ad43-848108254cd0\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "Nice to officially meet you, Ram! How can I assist you today?\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6abb5974264bd269"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T12:51:07.616165Z",
     "start_time": "2025-10-27T12:51:00.202730Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response = response_agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"John is my friend.\"}]},\n",
    "    config=config\n",
    ")"
   ],
   "id": "758e07e7867df4b0",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b00b540d8d602110"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T12:51:07.628204Z",
     "start_time": "2025-10-27T12:51:07.625034Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for m in response[\"messages\"]:\n",
    "    m.pretty_print()"
   ],
   "id": "b906f7b34b7b71d9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "John is my friend.\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  manage_memory (call_q8ybiEWc0wMt8ap44hdKZE96)\n",
      " Call ID: call_q8ybiEWc0wMt8ap44hdKZE96\n",
      "  Args:\n",
      "    content: John is a friend of Ram.\n",
      "    action: create\n",
      "=================================\u001B[1m Tool Message \u001B[0m=================================\n",
      "Name: manage_memory\n",
      "\n",
      "created memory cf24da75-9c22-4d66-8fd8-000db67cdb04\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "I've noted that John is your friend. If there's anything specific you'd like to remember or share about your friendship with him, feel free to let me know!\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "dc6685c175b96e9e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "* It's using the memory and returning the data from the prior conversations",
   "id": "cfe9444458d8271e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T12:51:15.567911Z",
     "start_time": "2025-10-27T12:51:12.608230Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response = response_agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Who is John?\"}]},\n",
    "    config=config\n",
    ")"
   ],
   "id": "a72420d72950ba30",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T12:51:15.584436Z",
     "start_time": "2025-10-27T12:51:15.580230Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for m in response[\"messages\"]:\n",
    "    m.pretty_print()"
   ],
   "id": "32507604da3f7fc1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "Who is John?\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  search_memory (call_03T96RTXqURzHsJw3vYs5QGo)\n",
      " Call ID: call_03T96RTXqURzHsJw3vYs5QGo\n",
      "  Args:\n",
      "    query: John\n",
      "=================================\u001B[1m Tool Message \u001B[0m=================================\n",
      "Name: search_memory\n",
      "\n",
      "[{\"namespace\":[\"memories\",\"session-id-test\",\"collection\"],\"key\":\"cf24da75-9c22-4d66-8fd8-000db67cdb04\",\"value\":{\"content\":\"John is a friend of Ram.\"},\"created_at\":\"2025-10-27T12:51:05.567081+00:00\",\"updated_at\":\"2025-10-27T12:51:05.567094+00:00\",\"score\":0.314446028352704},{\"namespace\":[\"memories\",\"session-id-test\",\"collection\"],\"key\":\"b5bb66e7-5f5d-4170-ad43-848108254cd0\",\"value\":{\"content\":\"User's name is Ram.\"},\"created_at\":\"2025-10-27T12:50:52.353626+00:00\",\"updated_at\":\"2025-10-27T12:50:52.353638+00:00\",\"score\":0.16457608233286636}]\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "John is a friend of Ram. If you need more specific information about him, feel free to ask!\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8f144d7ff6738cb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "* Please feel free to further experiment enhance wrt your use case\n",
    "* Use AsyncPostgresStore for prod\n",
    "    * We can auto-scale.\n",
    "    * Memory is safe even if instance is down.\n",
    "    * API memory doesn't keep increasing forever.\n",
    "    * <a href=\"https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.postgres.AsyncPostgresStore\">AsyncPostgresStore</a>"
   ],
   "id": "fa35398af9e9f3d3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "38e9697b751815b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
